diff --git a/Makefile b/Makefile
index c6a265b5..f7a2f663 100644
--- a/Makefile
+++ b/Makefile
@@ -597,6 +597,11 @@ endif # $(dot-config)
 # This allow a user to issue only 'make' to build a kernel including modules
 # Defaults to vmlinux, but the arch makefile usually adds further targets
 all: vmlinux
+# force no-pie for distro compilers that enable pie by default
+KBUILD_CFLAGS += $(call cc-option, -fno-pie)
+KBUILD_CFLAGS += $(call cc-option, -no-pie)
+KBUILD_AFLAGS += $(call cc-option, -fno-pie)
+KBUILD_CPPFLAGS += $(call cc-option, -fno-pie)
 
 # The arch Makefile can set ARCH_{CPP,A,C}FLAGS to override the default
 # values of the respective KBUILD_* variables
diff --git a/arch/x86/entry/entry_64.S b/arch/x86/entry/entry_64.S
index a55697d1..bb084c10 100644
--- a/arch/x86/entry/entry_64.S
+++ b/arch/x86/entry/entry_64.S
@@ -694,6 +694,8 @@ apicinterrupt3 POSTED_INTR_VECTOR		kvm_posted_intr_ipi		smp_kvm_posted_intr_ipi
 apicinterrupt3 POSTED_INTR_WAKEUP_VECTOR	kvm_posted_intr_wakeup_ipi	smp_kvm_posted_intr_wakeup_ipi
 #endif
 
+apicinterrupt IMM8_VECTOR        ck_exception_interrupt        smp_ck_exception_interrupt
+
 #ifdef CONFIG_X86_MCE_THRESHOLD
 apicinterrupt THRESHOLD_APIC_VECTOR		threshold_interrupt		smp_threshold_interrupt
 #endif
diff --git a/arch/x86/include/asm/entry_arch.h b/arch/x86/include/asm/entry_arch.h
index df002992..3bb9f8bf 100644
--- a/arch/x86/include/asm/entry_arch.h
+++ b/arch/x86/include/asm/entry_arch.h
@@ -27,6 +27,7 @@ BUILD_INTERRUPT3(kvm_posted_intr_wakeup_ipi, POSTED_INTR_WAKEUP_VECTOR,
 		 smp_kvm_posted_intr_wakeup_ipi)
 #endif
 
+BUILD_INTERRUPT(ck_exception_interrupt, IMM8_VECTOR)
 /*
  * every pentium local APIC has two 'local interrupts', with a
  * soft-definable vector attached to both interrupts, one of
diff --git a/arch/x86/include/asm/hardirq.h b/arch/x86/include/asm/hardirq.h
index 7178043b..d6cddfc9 100644
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@ -16,6 +16,7 @@ typedef struct {
 	unsigned int kvm_posted_intr_ipis;
 	unsigned int kvm_posted_intr_wakeup_ipis;
 #endif
+	unsigned int ck_exception_count;
 	unsigned int x86_platform_ipis;	/* arch dependent */
 	unsigned int apic_perf_irqs;
 	unsigned int apic_irq_work_irqs;
diff --git a/arch/x86/include/asm/hw_irq.h b/arch/x86/include/asm/hw_irq.h
index 1e3408e8..ab0705e2 100644
--- a/arch/x86/include/asm/hw_irq.h
+++ b/arch/x86/include/asm/hw_irq.h
@@ -30,6 +30,7 @@ extern asmlinkage void apic_timer_interrupt(void);
 extern asmlinkage void x86_platform_ipi(void);
 extern asmlinkage void kvm_posted_intr_ipi(void);
 extern asmlinkage void kvm_posted_intr_wakeup_ipi(void);
+extern asmlinkage void ck_exception_interrupt(void);
 extern asmlinkage void error_interrupt(void);
 extern asmlinkage void irq_work_interrupt(void);
 
@@ -48,6 +49,7 @@ extern asmlinkage void call_function_single_interrupt(void);
 #ifdef CONFIG_TRACING
 /* Interrupt handlers registered during init_IRQ */
 extern void trace_apic_timer_interrupt(void);
+extern void trace_ck_exception_interrupt(void);
 extern void trace_x86_platform_ipi(void);
 extern void trace_error_interrupt(void);
 extern void trace_irq_work_interrupt(void);
@@ -168,6 +170,7 @@ extern __visible void smp_apic_timer_interrupt(struct pt_regs *);
 extern __visible void smp_spurious_interrupt(struct pt_regs *);
 extern __visible void smp_x86_platform_ipi(struct pt_regs *);
 extern __visible void smp_error_interrupt(struct pt_regs *);
+extern __visible void smp_ck_exception_interrupt(struct pt_regs *);
 #ifdef CONFIG_X86_IO_APIC
 extern asmlinkage void smp_irq_move_cleanup_interrupt(void);
 #endif
diff --git a/arch/x86/include/asm/irq_vectors.h b/arch/x86/include/asm/irq_vectors.h
index 6ca9fd62..3ad41a60 100644
--- a/arch/x86/include/asm/irq_vectors.h
+++ b/arch/x86/include/asm/irq_vectors.h
@@ -100,6 +100,8 @@
 #define POSTED_INTR_VECTOR		0xf2
 #endif
 
+#define IMM8_VECTOR   	                0xcd
+
 /*
  * Local APIC timer IRQ vector is on a different priority level,
  * to work around the 'lost local interrupt if more than 2 IRQ
diff --git a/arch/x86/include/asm/trace/irq_vectors.h b/arch/x86/include/asm/trace/irq_vectors.h
index 38a09a13..4822411f 100644
--- a/arch/x86/include/asm/trace/irq_vectors.h
+++ b/arch/x86/include/asm/trace/irq_vectors.h
@@ -44,6 +44,8 @@ DEFINE_EVENT_FN(x86_irq_vector, name##_exit,	\
  */
 DEFINE_IRQ_VECTOR_EVENT(local_timer);
 
+DEFINE_IRQ_VECTOR_EVENT(ck_exception);
+
 /*
  * reschedule - called when entering/exiting a reschedule vector handler
  */
diff --git a/arch/x86/kernel/alternative.c b/arch/x86/kernel/alternative.c
index 25f90936..05a3e4e4 100644
--- a/arch/x86/kernel/alternative.c
+++ b/arch/x86/kernel/alternative.c
@@ -1,5 +1,6 @@
 #define pr_fmt(fmt) "SMP alternatives: " fmt
 
+ #include <linux/custom_kernel.h>
 #include <linux/module.h>
 #include <linux/sched.h>
 #include <linux/mutex.h>
diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index f8062aaf..30cf7d5e 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -163,6 +163,10 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 			   irq_stats(j)->kvm_posted_intr_wakeup_ipis);
 	seq_puts(p, "  Posted-interrupt wakeup event\n");
 #endif
+	seq_printf(p, "%*s: ", prec, "CK");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->ck_exception_count);
+	seq_puts(p, "  Custom kernel exceptions\n");
 	return 0;
 }
 
diff --git a/arch/x86/kernel/irqinit.c b/arch/x86/kernel/irqinit.c
index 1423ab1b..26db885c 100644
--- a/arch/x86/kernel/irqinit.c
+++ b/arch/x86/kernel/irqinit.c
@@ -152,6 +152,8 @@ static void __init apic_intr_init(void)
 	alloc_intr_gate(POSTED_INTR_WAKEUP_VECTOR, kvm_posted_intr_wakeup_ipi);
 #endif
 
+	alloc_intr_gate(IMM8_VECTOR, ck_exception_interrupt);
+
 	/* IPI vectors for APIC spurious and error interrupts */
 	alloc_intr_gate(SPURIOUS_APIC_VECTOR, spurious_interrupt);
 	alloc_intr_gate(ERROR_APIC_VECTOR, error_interrupt);
diff --git a/arch/x86/kernel/jump_label.c b/arch/x86/kernel/jump_label.c
index e565e0e4..16a11486 100644
--- a/arch/x86/kernel/jump_label.c
+++ b/arch/x86/kernel/jump_label.c
@@ -52,16 +52,18 @@ static void __jump_label_transform(struct jump_entry *entry,
 			 * So we expect a default_nop...
 			 */
 			if (unlikely(memcmp((void *)entry->code, default_nop, 5)
-				     != 0))
-				bug_at((void *)entry->code, __LINE__);
+				     != 0)) {}
+        /* Do not trigger bug_at with jump_label  */
+				/* bug_at((void *)entry->code, __LINE__); */
 		} else {
 			/*
 			 * ...otherwise expect an ideal_nop. Otherwise
 			 * something went horribly wrong.
 			 */
 			if (unlikely(memcmp((void *)entry->code, ideal_nop, 5)
-				     != 0))
-				bug_at((void *)entry->code, __LINE__);
+				     != 0)) {}
+        /* Do not trigger bug_at with jump_label  */
+				/* bug_at((void *)entry->code, __LINE__); */
 		}
 
 		code.jump = 0xe9;
@@ -76,13 +78,17 @@ static void __jump_label_transform(struct jump_entry *entry,
 		 */
 		if (init) {
 			if (unlikely(memcmp((void *)entry->code, default_nop, 5) != 0))
-				bug_at((void *)entry->code, __LINE__);
+      {}
+        /* Do not trigger bug_at with jump_label  */
+				/* bug_at((void *)entry->code, __LINE__); */
 		} else {
 			code.jump = 0xe9;
 			code.offset = entry->target -
 				(entry->code + JUMP_LABEL_NOP_SIZE);
 			if (unlikely(memcmp((void *)entry->code, &code, 5) != 0))
-				bug_at((void *)entry->code, __LINE__);
+      {}
+        /* Do not trigger bug_at with jump_label  */
+				/* bug_at((void *)entry->code, __LINE__); */
 		}
 		memcpy(&code, ideal_nops[NOP_ATOMIC5], JUMP_LABEL_NOP_SIZE);
 	}
diff --git a/fs/exec.c b/fs/exec.c
index b06623a9..e5a0a19c 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -56,6 +56,7 @@
 #include <linux/pipe_fs_i.h>
 #include <linux/oom.h>
 #include <linux/compat.h>
+#include <linux/custom_kernel.h>
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
@@ -1490,6 +1491,7 @@ static int do_execveat_common(int fd, struct filename *filename,
 	struct linux_binprm *bprm;
 	struct file *file;
 	struct files_struct *displaced;
+	struct ck_info *ck_info;
 	int retval;
 
 	if (IS_ERR(filename))
@@ -1587,6 +1589,20 @@ static int do_execveat_common(int fd, struct filename *filename,
 	if (retval < 0)
 		goto out;
 
+	printk(KERN_DEBUG "\n(%s)bprm->mm %p\n", bprm->filename, bprm->mm);
+	if (is_ck(current->mm)) {
+		inherent_ck(bprm->mm, current->mm);
+		BUG_ON(bprm->mm->pgd[511].pgd == init_mm.pgd[511].pgd);
+		printk(KERN_INFO "%s USE PARENT KERNEL\n", bprm->filename);
+	} else if ((ck_info = get_ck_info(bprm->file)) != NULL) {
+		load_ck(bprm->mm, ck_info);
+		BUG_ON(bprm->mm->pgd[511].pgd == init_mm.pgd[511].pgd);
+		printk(KERN_INFO "%s USE CUSTOM KERNEL\n", bprm->filename);
+	} else {
+		bprm->mm->ck = NULL;
+		printk(KERN_INFO "%s USE KERNEL 0\n", bprm->filename);
+	}
+
 	retval = exec_binprm(bprm);
 	if (retval < 0)
 		goto out;
diff --git a/include/linux/custom_kernel.h b/include/linux/custom_kernel.h
new file mode 100644
index 00000000..d86d0fab
--- /dev/null
+++ b/include/linux/custom_kernel.h
@@ -0,0 +1,54 @@
+#ifndef _CUSTOM_KERNEL_H
+#define _CUSTOM_KERNEL_H
+
+#include <linux/gfp.h>
+#include <asm/pgtable.h>
+#include <linux/proc_fs.h>
+#include <linux/uaccess.h>
+#include <linux/binfmts.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/interrupt.h>
+#include <asm/setup.h>
+#include <asm/sections.h>
+#include <asm/hw_irq.h>
+
+#define PGALLOC_GFP (__GFP_ZERO)
+#define KERNEL0_TEXT ((unsigned long) _text)
+#define KERNEL0_TEXT_END (PFN_ALIGN(((unsigned long) _etext)))
+#define CUSTOM_KTEXT_REGION_SIZE (KERNEL0_TEXT_END - KERNEL0_TEXT)
+#define PMD_PTRS_PER_REGION (CUSTOM_KTEXT_REGION_SIZE >> PMD_SHIFT)
+
+#define __FILENAME_MAX_SIZE 64
+#define __MAX_BLK_CNT 40960
+
+struct ck_info {
+	unsigned long i_ino;
+	unsigned int blk_cnt;
+	struct blk_info *blks;
+	struct list_head list;
+};
+
+struct ck_struct {
+	void* addr;
+	pmd_t *new_pmd;
+	pud_t *new_pud;
+	/* Just like mm_count which is the number of references */
+	atomic_t ck_count;
+	struct ck_info *info;
+};
+
+struct blk_info {
+	unsigned int offset;
+	unsigned int size;
+};
+
+extern int load_ck(struct mm_struct*, struct ck_info*);
+extern int init_custom_proc(void);
+extern struct ck_info* get_ck_info(const struct file*);
+extern int put_ck(struct mm_struct*);
+extern inline int inherent_ck(struct mm_struct *child, struct mm_struct *parent);
+extern inline int is_ck(struct mm_struct*);
+
+
+#endif
diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index f8d1492a..fe6d793b 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -402,6 +402,9 @@ struct mm_struct {
 	unsigned long mmap_legacy_base;         /* base of mmap area in bottom-up allocations */
 	unsigned long task_size;		/* size of task vm space */
 	unsigned long highest_vm_end;		/* highest vma end address */
+        /* Custom kernel metadata start*/
+	struct ck_struct *ck;
+	/* Custom kernel metadata end*/
 	pgd_t * pgd;
 	atomic_t mm_users;			/* How many users with user space? */
 	atomic_t mm_count;			/* How many references to "struct mm_struct" (users count as 1) */
diff --git a/init/main.c b/init/main.c
index 9e64d709..bbbf52af 100644
--- a/init/main.c
+++ b/init/main.c
@@ -11,6 +11,7 @@
 
 #define DEBUG		/* Enable initcall_debug */
 
+#include <linux/custom_kernel.h>
 #include <linux/types.h>
 #include <linux/module.h>
 #include <linux/proc_fs.h>
@@ -883,6 +884,7 @@ static void __init do_basic_setup(void)
 	do_ctors();
 	usermodehelper_enable();
 	do_initcalls();
+	init_custom_proc();
 	random_int_secret_init();
 }
 
diff --git a/kernel/Makefile b/kernel/Makefile
index 53abf008..274b17c1 100644
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -29,6 +29,7 @@ obj-y += printk/
 obj-y += irq/
 obj-y += rcu/
 obj-y += livepatch/
+obj-y += custom_kernel.o
 
 obj-$(CONFIG_CHECKPOINT_RESTORE) += kcmp.o
 obj-$(CONFIG_FREEZER) += freezer.o
diff --git a/kernel/custom_kernel.c b/kernel/custom_kernel.c
new file mode 100644
index 00000000..2e0629c0
--- /dev/null
+++ b/kernel/custom_kernel.c
@@ -0,0 +1,347 @@
+#include <linux/custom_kernel.h>
+#include <asm/trace/irq_vectors.h>
+#include <linux/sched.h>
+#ifndef pr_fmt
+#define pr_fmt(fmt) "CustomKernel: " fmt
+#endif
+static ssize_t custom_read(struct file *file, char __user * buffer,
+		size_t count, loff_t * data);
+static ssize_t custom_write(struct file *file, const char __user * buffer, size_t count, loff_t * data); static ssize_t blk_read(struct file *file, char __user * buffer,
+		size_t count, loff_t * data);
+static ssize_t blk_write(struct file *file, const char __user * buffer,
+		size_t count, loff_t * data);
+static const struct file_operations custom_fops = {
+	.read = custom_read,
+	.write = custom_write
+};
+static const struct file_operations blk_fops = {
+	.read = blk_read,
+	.write = blk_write
+};
+static struct proc_dir_entry *ck_entry, *ck_mask;
+static LIST_HEAD(custom_list);
+struct tasklet_struct *ck_tasklet;
+
+/* impl */
+static inline void __free_blks(struct ck_info *info)
+{
+	vfree(info->blks);
+	info->blks = NULL;
+	return;
+}
+static void __clear_list(void) { struct ck_info *pos, *tmp;
+	char entry[32];
+	list_for_each_entry_safe(pos, tmp, &custom_list, list) {
+		list_del(&pos->list);
+		sprintf(entry, "%lu", pos->i_ino);
+		remove_proc_entry(entry , ck_mask);
+		__free_blks(pos);
+		vfree(pos);
+	}
+}
+static ssize_t custom_read(struct file *file, char __user * buffer,
+		size_t count, loff_t * data)
+{
+	struct ck_info *info;
+	ssize_t copied;
+	char *vbuf;
+	int copy_failed;
+	vbuf = (char *)vmalloc(count);
+	vbuf[0] = '\0';
+	copied = 0;
+	if ((long)*data > 0)
+		return 0;
+	if (list_empty(&custom_list))
+		return 0;
+	list_for_each_entry(info, &custom_list, list) {
+		char tmpbuf[__FILENAME_MAX_SIZE + 1];
+		sprintf(tmpbuf, "%lu\n", info->i_ino);
+		copied += strlen(tmpbuf);
+		strcat(vbuf, tmpbuf);
+	}
+	copy_failed = copy_to_user(buffer, vbuf, strlen(vbuf));
+	if (copy_failed)
+		return -ENOMEM;
+	*data += copied;
+	vfree(vbuf);
+	return copied;
+}
+static ssize_t custom_write(struct file *file, const char __user * buffer, size_t count, loff_t * data)
+{
+	int pos = 0;
+	int char_read = 0;
+	unsigned long inode_num = 0;
+	char *kbuf;
+	char mname[__FILENAME_MAX_SIZE];
+	struct ck_info *info;
+	if ((long)*data > 0)
+		return 0;
+	__clear_list();
+	kbuf = vmalloc(count);
+	if (copy_from_user(kbuf, buffer, count))
+		return -EFAULT;
+	kbuf[count] = '\0';
+	kbuf = strim(kbuf);
+	/* while ((i_ino_str = strsep(&kbuf_dup, ",")) != NULL) { */
+	while(sscanf(kbuf+pos, "%lu%n", &inode_num, &char_read) == 1) {
+		sprintf(mname, "%lu", inode_num);
+		info = vmalloc(sizeof(struct ck_info));
+		info->i_ino = inode_num;
+		info->blks = vmalloc(__MAX_BLK_CNT * sizeof(struct blk_info));
+		info->blk_cnt = 0;
+		if (!proc_create_data(mname, 666, ck_mask, &blk_fops, info)) {
+			vfree(kbuf);
+			return 0;
+		}
+		list_add_tail(&info->list, &custom_list);
+		pos += char_read;
+	}
+	vfree(kbuf);
+	*data += count;
+	return count;
+}
+static ssize_t blk_write(struct file *file, const char __user * buffer,
+		size_t count, loff_t * data)
+{
+	int pos = 0;
+	int char_read = 0;
+	char *kbuf; //, *blk_info_str;
+	struct ck_info *info;
+	struct blk_info *blk;
+	unsigned int offset, size;
+
+	if ((long)*data > 0)
+		return 0;
+	if (count > 2048)
+		count = 2048;
+	info = PDE_DATA(file_inode(file));
+	kbuf = vmalloc(count);
+	if (copy_from_user(kbuf, buffer, count))
+		return -EFAULT;
+	kbuf[count] = '\0';
+	kbuf = strim(kbuf);
+	while(sscanf(kbuf+pos, "%x,%x\n%n", &offset, &size, &char_read) == 2) {
+		pos += char_read;
+		if (offset + size >= CUSTOM_KTEXT_REGION_SIZE) {
+			pr_warn("Skip invalid blk %x, %x\n", offset, size);
+			continue;
+		}
+		blk = info->blks + info->blk_cnt;
+		blk->offset = offset;
+		blk->size = size;
+		info->blk_cnt++;
+	}
+	vfree(kbuf);
+	*data += count;
+	return count;
+}
+static ssize_t blk_read(struct file *file, char __user * buffer,
+		size_t count, loff_t * data)
+{
+	struct ck_info *info;
+	ssize_t len = 0;
+	char *vbuf;
+	int copy_failed;
+	info = PDE_DATA(file_inode(file));
+	vbuf = (char *)vmalloc(count);
+	vbuf[0] = '\0';
+	if ((long)*data > 0)
+		return 0;
+	len = sprintf(vbuf, "blk_cnt: %u\n", info->blk_cnt);
+	copy_failed = copy_to_user(buffer, vbuf, strlen(vbuf));
+	if (copy_failed)
+		return -ENOMEM;
+	*data += len;
+	vfree(vbuf);
+	return len;
+}
+int init_custom_proc(void)
+{
+	ck_entry = proc_create("ck_ctl", 666, NULL, &custom_fops);
+	ck_mask = proc_mkdir("ck_mask", NULL);
+	ck_tasklet = vmalloc(sizeof(struct tasklet_struct));
+	if (!ck_entry) {
+		printk(KERN_INFO "Error creating proc entry");
+		return -ENOMEM;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(init_custom_proc);
+struct ck_info* get_ck_info(const struct file* file)
+{
+	struct ck_info *info;
+	unsigned long i_ino = file_inode(file)->i_ino;
+	list_for_each_entry(info, &custom_list, list) {
+		if (i_ino == info->i_ino)
+			return info;
+	}
+	return NULL;
+}
+EXPORT_SYMBOL(get_ck_info);
+static int __link_to_new_kernel(struct mm_struct *mm)
+{
+	unsigned long addr = (unsigned long) mm->ck->addr;
+	pgd_t *pgd = pgd_offset_k(addr);
+	pgd_t *m_pgd = pgd_offset(mm, KERNEL0_TEXT);
+	if (!pgd_none(*pgd) || !pgd_none(*m_pgd)) {
+		pud_t *pud = pud_offset(pgd, addr);
+		pud_t *m_pud = pud_offset(m_pgd, KERNEL0_TEXT);
+		if (!pud_none(*pud) || !pud_none(*m_pud)) {
+			pmd_t *pmd = pmd_offset(pud, addr);
+			pmd_t *m_pmd = pmd_offset(m_pud, KERNEL0_TEXT);
+			pr_debug("pmd %lx\tm_pmd %lx ptr per region %lx\n", pmd->pmd, m_pmd->pmd, PMD_PTRS_PER_REGION);
+			pr_debug("KERNEL0_TEXT pmd idx %lx pte idx %lx\n", pmd_index(KERNEL0_TEXT), pte_index(KERNEL0_TEXT));
+			pr_debug("addr pmd idx %lx pte idx %lx\n", pmd_index(addr), pte_index(addr));
+			memcpy(m_pmd, pmd, PMD_PTRS_PER_REGION * sizeof(pmd_t));
+			pr_debug("pmd %lx\tm_pmd %lx\n", pmd->pmd, m_pmd->pmd);
+		} else
+			goto fail;
+	} else
+		goto fail;
+	return 0;
+fail:
+	BUG();
+	return 1;
+}
+static int __prepare_custom_page_tables(struct mm_struct *mm)
+{
+	pgd_t *pgd;
+	pud_t *new_pud, *pud;
+	pmd_t *new_pmd, *pmd;
+	new_pud = mm->ck->new_pud;
+	new_pmd = mm->ck->new_pmd;
+	pgd = pgd_offset(mm, KERNEL0_TEXT);
+	BUG_ON(pgd_none(*pgd));
+	pud = pud_offset(pgd, 0);
+	memcpy(new_pud, pud, PTRS_PER_PUD * sizeof(pud_t));
+	pud = pud_offset(pgd, KERNEL0_TEXT);
+	BUG_ON(pud_none(*pud));
+	pmd = pmd_offset(pud, 0);
+	memcpy(new_pmd, pmd, PTRS_PER_PMD  * sizeof(pmd_t));
+	set_pud(new_pud + 510, __pud(_KERNPG_TABLE | __pa(new_pmd)));
+	set_pgd(pgd, __pgd(_KERNPG_TABLE | __pa(new_pud)));
+	return 0;
+}
+static int __mask_ck(struct mm_struct *mm)
+{
+	unsigned char maskchr = 0xcd;
+	struct ck_info *info = mm->ck->info;
+	unsigned int offset, size, i;
+	unsigned char* addr;
+	for(i = 0; i < info->blk_cnt; i++) {
+		offset = info->blks[i].offset;
+		size = info->blks[i].size;
+		addr = mm->ck->addr + offset;
+		BUG_ON(offset + size >= CUSTOM_KTEXT_REGION_SIZE);
+		memset(addr, maskchr, size);
+	}
+	pr_info("Finished Masking %d blocks\n", info->blk_cnt);
+	return 0;
+}
+static int __init_ck(struct mm_struct *mm)
+{
+	void* addr = __vmalloc(CUSTOM_KTEXT_REGION_SIZE + (1 << 21),
+			GFP_KERNEL | __GFP_ZERO,
+			PAGE_KERNEL_EXEC);
+	mm->ck = vmalloc(sizeof(struct ck_struct));
+	atomic_set(&mm->ck->ck_count, 0);
+	addr = (void*) ALIGN((unsigned long) addr, PMD_SIZE);
+	memcpy((void*) addr, (void*) KERNEL0_TEXT, CUSTOM_KTEXT_REGION_SIZE);
+	mm->ck->addr = addr;
+	mm->ck->new_pud = (pud_t *) __get_free_page(PGALLOC_GFP);
+	mm->ck->new_pmd = (pmd_t *) __get_free_page(PGALLOC_GFP);
+	return 0;
+}
+int inherent_ck(struct mm_struct *child, struct mm_struct *parent)
+{
+	set_pgd(child->pgd + 511, __pgd(_KERNPG_TABLE | __pa(parent->ck->new_pud)));
+	child->ck = parent->ck;
+	atomic_inc(&child->ck->ck_count);
+	return 0;
+}
+EXPORT_SYMBOL(inherent_ck);
+int put_ck(struct mm_struct *mm)
+{
+	struct ck_struct *ck = mm->ck;
+	if (atomic_dec_and_test(&ck->ck_count)) {
+		free_page((unsigned long) ck->new_pud);
+		free_page((unsigned long) ck->new_pmd);
+		vfree(ck->addr);
+		vfree(ck);
+
+	}
+	mm->ck = NULL;
+	return 0;
+}
+EXPORT_SYMBOL(put_ck);
+int load_ck(struct mm_struct *mm, struct ck_info *info)
+{
+	pgd_t* pgd;
+	pud_t* pud;
+	pmd_t* pmd;
+	pte_t* pte;
+	void *addr = NULL;
+	BUG_ON(__init_ck(mm));
+	mm->ck->info = info;
+	BUG_ON(__mask_ck(mm));
+	BUG_ON(__prepare_custom_page_tables(mm));
+	BUG_ON(__link_to_new_kernel(mm));
+	addr = mm->ck->addr;
+	atomic_inc(&mm->ck->ck_count);
+	/* Verify correctly mapped */
+	pgd = pgd_offset(mm, KERNEL0_TEXT);
+	pud = pud_offset(pgd, KERNEL0_TEXT);
+	pmd = pmd_offset(pud, KERNEL0_TEXT);
+	pte = pte_offset_map(pmd, KERNEL0_TEXT);
+	pr_debug("vmalloc_to_pfn(addr)-> %lx, pte[0].pte %lx\n",
+			vmalloc_to_pfn(addr), pte[0].pte);
+	BUG_ON(vmalloc_to_pfn(addr) != pte[0].pte >> PAGE_SHIFT);
+	pte_unmap(pte);
+	return 0;
+}
+EXPORT_SYMBOL(load_ck);
+int is_ck(struct mm_struct *mm)
+{
+	if(!mm)
+		return 0;
+	return mm->ck != NULL;
+}
+EXPORT_SYMBOL(is_ck);
+
+static void do_kill(unsigned long data)
+{
+	struct task_struct *task = (struct task_struct*) data;
+	set_task_state(task, TASK_UNINTERRUPTIBLE);
+	schedule();
+}
+
+static void local_ck_exception_interrupt(void)
+{
+	inc_irq_stat(ck_exception_count);
+	tasklet_init(ck_tasklet, do_kill, (unsigned long)current);
+	tasklet_hi_schedule(ck_tasklet);
+}
+
+__visible void smp_ck_exception_interrupt(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	entering_ack_irq();
+	local_ck_exception_interrupt();
+	exiting_irq();
+
+	set_irq_regs(old_regs);
+}
+
+__visible void smp_trace_ck_exception_interrupt(struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	entering_ack_irq();
+	trace_ck_exception_entry(IMM8_VECTOR);
+	local_ck_exception_interrupt();
+	trace_ck_exception_exit(IMM8_VECTOR);
+	exiting_irq();
+
+	set_irq_regs(old_regs);
+}
diff --git a/kernel/fork.c b/kernel/fork.c
index 1155eac6..7d020d66 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -11,6 +11,7 @@
  * management can be a bitch. See 'mm/memory.c': 'copy_page_range()'
  */
 
+#include <linux/custom_kernel.h>
 #include <linux/slab.h>
 #include <linux/init.h>
 #include <linux/unistd.h>
@@ -685,6 +686,8 @@ void __mmdrop(struct mm_struct *mm)
 	destroy_context(mm);
 	mmu_notifier_mm_destroy(mm);
 	check_mm(mm);
+	if (mm->ck)
+		put_ck(mm);
 	free_mm(mm);
 }
 EXPORT_SYMBOL_GPL(__mmdrop);
@@ -982,6 +985,10 @@ static int copy_mm(unsigned long clone_flags, struct task_struct *tsk)
 	if (!mm)
 		goto fail_nomem;
 
+	if (is_ck(current->mm)) {
+		inherent_ck(mm, current->mm);
+	}
+
 good_mm:
 	tsk->mm = mm;
 	tsk->active_mm = mm;
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 732e993b..f7b249ab 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -2680,9 +2680,9 @@ context_switch(struct rq *rq, struct task_struct *prev,
 	arch_start_context_switch(prev);
 
 	if (!mm) {
-		next->active_mm = oldmm;
-		atomic_inc(&oldmm->mm_count);
-		enter_lazy_tlb(oldmm, next);
+		next->active_mm = &init_mm;
+		atomic_inc(&init_mm.mm_count);
+		switch_mm(oldmm, &init_mm, next);
 	} else
 		switch_mm(oldmm, mm, next);
 
diff --git a/tools/perf/bench/futex.h b/tools/perf/bench/futex.h
index d44de9f4..34b2545b 100644
--- a/tools/perf/bench/futex.h
+++ b/tools/perf/bench/futex.h
@@ -12,6 +12,11 @@
 #include <sys/types.h>
 #include <linux/futex.h>
 
+#ifndef SYS_futex
+#define SYS_futex __NR_futex
+#endif
+
+
 /**
  * futex() - SYS_futex syscall wrapper
  * @uaddr:	address of first futex
diff --git a/tools/perf/config/Makefile b/tools/perf/config/Makefile
index de89ec57..f5ddec95 100644
--- a/tools/perf/config/Makefile
+++ b/tools/perf/config/Makefile
@@ -124,11 +124,6 @@ ifeq ($(call get-executable,$(BISON)),)
   dummy := $(error Error: $(BISON) is missing on this system, please install it)
 endif
 
-# Treat warnings as errors unless directed not to
-ifneq ($(WERROR),0)
-  CFLAGS += -Werror
-endif
-
 ifndef DEBUG
   DEBUG := 0
 endif
diff --git a/tools/perf/tests/tests.h b/tools/perf/tests/tests.h
index 3c8734a3..b77969c6 100644
--- a/tools/perf/tests/tests.h
+++ b/tools/perf/tests/tests.h
@@ -1,6 +1,10 @@
 #ifndef TESTS_H
 #define TESTS_H
 
+#ifndef SYS_gettid
+#define SYS_gettid __NR_gettid
+#endif
+
 #define TEST_ASSERT_VAL(text, cond)					 \
 do {									 \
 	if (!(cond)) {							 \
